{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using graphics cards to solve forward and inverse problems in geodynamics\n",
    "\n",
    "#### 2022 Ada Lovelace Workshop\n",
    "#### HÃ©vÃ­z | Hungary | 28 Augustâ€“2 September 2022\n",
    "\n",
    "### Ludovic RÃ¤ss & Ivan Utkin\n",
    "\n",
    "![eth logo](./figures/logo2.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What we will achieve today\n",
    "\n",
    "Inversion for viscosity in a free-surface channel flow\n",
    "\n",
    "![inversion](./figures/inversion.gif)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The (yet invisible) cool stuff\n",
    "\n",
    "The code used to produce the inversion\n",
    "- Runs on graphics cards using the Julia language\n",
    "- Uses a fully local and iterative approach (scalability)\n",
    "- Retrieves automatically the \"inverse\" (adjoint) variables using automatic differentiation (AD)\n",
    "- (Features 340 lines of code - 3 solvers + GD)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Too good to be true? Hold on ðŸ™‚ ..."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why to still bother with GPU computing in 2022\n",
    "\n",
    "- It's around for more than a decade\n",
    "- Shows massive performance gain compared to serial CPU computing\n",
    "- First exascale supercomputer, Frontier, is full of GPUs\n",
    "\n",
    "![Frontier](./figures/frontier.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance that matters\n",
    "\n",
    "![cpu_gpu_evo](./figures/cpu_gpu_evo.png)\n",
    "\n",
    "Taking a look at a recent GPU and CPU:\n",
    "- Nvidia Tesla A100 GPU\n",
    "- AMD EPYC \"Rome\" 7282 (16 cores) CPU\n",
    "\n",
    "| Device         | TFLOP/s (FP64) | Memory BW TB/s | Imbalance (FP64)     |\n",
    "| :------------: | :------------: | :------------: | :------------------: |\n",
    "| Tesla A100     | 9.7            | 1.55           | 9.7 / 1.55  Ã— 8 = 50 |\n",
    "| AMD EPYC 7282  | 0.7            | 0.085          | 0.7 / 0.085 Ã— 8 = 66 |"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Meaning:** we can do about 50 floating point operations per number accessed from main memory.\n",
    "Floating point operations are \"for free\" when we work in memory-bounded regimes.\n",
    "\n",
    "ðŸ‘‰ Requires to re-think the numerical implementation and solution strategies"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, the cost of evaluating a first derivative $âˆ‚A / âˆ‚x$ using finite-differences\n",
    "\n",
    "```julia\n",
    "q[ix] = -D*(A[ix+1]-A[ix])/dx\n",
    "```\n",
    "\n",
    "consists of:"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 1 reads + 1 write => $2 Ã— 8$ = **16 Bytes transferred**\n",
    "- 1 (fused) addition and division => **1 floating point operations**\n",
    "\n",
    "ðŸ‘‰ assuming $D$, $âˆ‚x$ are scalars, $q$ and $A$ are arrays of `Float64` (read from main memory)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance that matters\n",
    "\n",
    "Not yet convinced?"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance comparison between the pseudo-transient (PT) and direct-iterative (DI) method resolving\n",
    "2D shear-band formation out of a random noise cohesion field.\n",
    "\n",
    "![pt_plastic2d](./figures/pt_plastic2d.png)\n",
    "\n",
    "RÃ¤ss et al. (2022) - https://doi.org/10.1029/2019GC008531"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance that matters - an example\n",
    "\n",
    "Not yet convinced? Let's create have a look as an example.\n",
    "\n",
    "Let's assess how close from memory copy (1355 GB/s) we can get solving a 2D diffusion problem on an Nvidia Tesla A100 GPU.\n",
    "\n",
    "$$ âˆ‡â‹…(D âˆ‡ C) = \\frac{âˆ‚C}{âˆ‚t} $$"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CUDA,BenchmarkTools\n",
    "using ParallelStencil,ParallelStencil.FiniteDifferences2D\n",
    "@init_parallel_stencil(CUDA,Float64,2)\n",
    "CUDA.device!(7) # select specific GPU\n",
    "nx = ny = 512*64\n",
    "C  = @rand(nx,ny)\n",
    "D  = @rand(nx,ny)\n",
    "dx = dy = dt = rand(); C2 = copy(T)\n",
    "@parallel function diffusion_step!(C2, C, D, dt, dx, dy)\n",
    "    @inn(T2) = @inn(T) + dt*@inn(D)*(@d2_xi(T)/dx/dx + @d2_yi(T)/dy/dy)\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now sample the performance on the GPU:"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "t_it = @belapsed begin @parallel diffusion_step!($C2, $C, $D, $dt, $dx, $dy); end\n",
    "T_eff = (2*1+1)*1/1e9*nx*ny*sizeof(Float64)/t_it\n",
    "println(\"T_eff = $(T_eff) GiB/s using ParallelStencil on Nvidia A100 GPU\")\n",
    "println(\"So that's cool. We are getting close to hardware limit, running at $(T_eff_psind/1355) % of memory copy! ðŸš€\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why to still bother with GPU computing in 2022\n",
    "\n",
    "Because it is still challenging"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why?\n",
    "- Very few software uses it efficiently\n",
    "- It requires to rethink the solving strategy as non-local operations will kill the fun"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## That's what we address in this workshop\n",
    "- We show that both forward and inverse solvers can efficiently run on GPUs\n",
    "- We demonstrate it by making an inversion of shear-driven Stokes flow\n",
    "- We develop all this using the Julia language as it solves the \"two-language problem\""
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outline\n",
    "1. The accelerated pseudo-transient (PT) method - a physics-motivated explanation\n",
    "2. Application of the PT method to GPU supercomputing\n",
    "3. Revisiting the adjoint method implementation using automatic differentiation (AD) and the PT method\n",
    "4. Application: Point-wise inversion for power-law prefactor in a free-surface channel flow\n",
    "5. Outlook and conclusion\n",
    "6. Curious? Some useful resources"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. The accelerated pseudo-transient (PT) method\n",
    "A physics-motivated explanation\n",
    "\n",
    "Ivan"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Application of the PT method to GPU supercomputing\n",
    "Resolving nonlinear mechanical problems with elasto-viscoplastic rheology in 3D\n",
    "\n",
    "![pt_plastic3d](./figures/pt_plastic3d.png)\n",
    "\n",
    "RÃ¤ss et al. (2022) - https://doi.org/10.1029/2019GC008531"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scalability of the accelerated PT method I\n",
    "\n",
    "Iteration count normalised by number of grid points in x-direction to remain mostly constant as function of `nx`.\n",
    "\n",
    "![pt_iter_scale](./figures/pt_iter_scale.png)\n",
    "\n",
    "RÃ¤ss et al. (2022) - https://doi.org/10.1029/2019GC008531"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scalability of the accelerated PT method II\n",
    "\n",
    "Next, as the PT algorithm is fully local, we achieve ideal parallel efficiency on 2000 GPUs.\n",
    "\n",
    "![pt_multigpu](./figures/pt_multigpu.png)\n",
    "\n",
    "We use asynchronous GPU function execution to hide MPI communication behind computations. A ready.to-use feature in [`ImplicitGlobalGrid.jl`](https://github.com/eth-cscs/ImplicitGlobalGrid.jl).\n",
    "\n",
    "RÃ¤ss et al. (2022) - https://doi.org/10.1029/2019GC008531"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Revisiting the adjoint method implementation\n",
    "Using automatic differentiation (AD) and the PT method\n",
    "\n",
    "Ivan"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The adjoint method\n",
    "\n",
    "![adjoint_inv](./figures/adjoint_inv.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automatic differentiation and the PT method\n",
    "\n",
    "![adjoint_pt_ad](./figures/adjoint_pt_ad.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AD approach in Julia\n",
    "\n",
    "![adjoint_julia_tools](./figures/adjoint_julia_tools.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Application\n",
    "Point-wise inversion for power-law prefactor in a free-surface channel flow\n",
    "\n",
    "Inversion for viscosity in a free-surface channel flow\n",
    "\n",
    "![inversion](./figures/inversion.gif)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Outlook and conclusion"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Curious?\n",
    "Some useful resources"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "kernelspec": {
   "name": "julia-1.8",
   "display_name": "Julia 1.8.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
